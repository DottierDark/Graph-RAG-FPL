#!/usr/bin/env python3
"""
Embedding Management Script
===========================
Comprehensive tool for managing embeddings in FPL Graph-RAG system.

Features:
- Create embeddings with progress tracking
- Compare different embedding models
- Check cache status
- Clear and rebuild cache
- Benchmark performance

Usage:
    python manage_embeddings.py create          # Create embeddings
    python manage_embeddings.py status          # Check cache status
    python manage_embeddings.py compare         # Compare models
    python manage_embeddings.py clear           # Clear cache
    python manage_embeddings.py benchmark       # Run benchmarks
"""

import sys
import os
import time
from pathlib import Path
from dotenv import load_dotenv

# Load environment
load_dotenv()

# Import optimized retriever
try:
    from .graph_retrieval_optimized import FPLGraphRetriever
except ImportError:
    print("‚ö†Ô∏è Using standard graph_retrieval.py")
    from .graph_retrieval import FPLGraphRetriever


class EmbeddingManager:
    """Manages embedding operations for FPL Graph-RAG"""
    
    def __init__(self):
        print("üîß Initializing Embedding Manager...")
        self.retriever = FPLGraphRetriever(
            uri=os.getenv("NEO4J_URI"),
            username=os.getenv("NEO4J_USERNAME"),
            password=os.getenv("NEO4J_PASSWORD")
        )
        print("‚úÖ Connected to Neo4j")
    
    def create_embeddings(self, batch_size=64, max_players=None):
        """Create embeddings for all players (default: ALL ~1600 players)"""
        print("\n" + "="*60)
        print("CREATE EMBEDDINGS FOR FULL DATASET")
        print("="*60)
        print(f"Processing: {'ALL ~1600 players' if not max_players else f'{max_players} players'}")
        print(f"Batch size: {batch_size} (optimized for large dataset)")
        print()
        
        count = self.retriever.create_node_embeddings(
            batch_size=batch_size,
            max_players=max_players
        )
        
        if count > 0:
            print(f"\n‚úÖ Successfully created {count} embeddings")
        else:
            print("\n‚ùå No embeddings created. Check Neo4j data.")
        
        return count
    
    def check_status(self):
        """Check embedding cache status"""
        print("\n" + "="*60)
        print("EMBEDDING STATUS")
        print("="*60)
        
        if hasattr(self.retriever, 'get_cache_info'):
            info = self.retriever.get_cache_info()
            
            print(f"\nüìä Cache Information:")
            print(f"   Model: {info.get('model', 'N/A')}")
            print(f"   Dimension: {info.get('dimension', 'N/A')}D")
            print(f"   Cache Directory: {info.get('cache_dir', 'N/A')}")
            print(f"   Cache Exists: {'‚úÖ' if info.get('cache_exists') else '‚ùå'}")
            print(f"   Embeddings Loaded: {'‚úÖ' if info.get('embeddings_loaded') else '‚ùå'}")
            print(f"   Number of Players: {info.get('num_players', 0)}")
            
            if 'created_at' in info:
                print(f"   Created At: {info['created_at']}")
        else:
            print("\n‚ö†Ô∏è Using basic retriever without cache info")
            print(f"   Embeddings Ready: {'‚úÖ' if self.retriever.is_embeddings_ready() else '‚ùå'}")
        
        print()
    
    def compare_models(self, query="top forwards", top_k=5):
        """Compare different embedding models"""
        print("\n" + "="*60)
        print("COMPARE EMBEDDING MODELS")
        print("="*60)
        print(f"Query: {query}")
        print()
        
        models = [
            "sentence-transformers/all-MiniLM-L6-v2",  # 384D, fast
            "sentence-transformers/all-mpnet-base-v2",  # 768D, better quality
        ]
        
        if hasattr(self.retriever, 'compare_embedding_models'):
            comparison = self.retriever.compare_embedding_models(query, models, top_k)
            
            print("\nüìä Results:")
            print("-" * 60)
            
            for model, results in comparison.items():
                model_name = model.split('/')[-1]
                print(f"\n{model_name}:")
                
                if 'error' in results:
                    print(f"  ‚ùå {results['error']}")
                    continue
                
                print(f"  Dimension: {results['dimension']}D")
                print(f"  Response Time: {results['response_time']:.3f}s")
                print(f"  Results Found: {results['num_results']}")
                print(f"  Avg Similarity: {results['avg_similarity']:.3f}")
                
                if results['top_results']:
                    print(f"  Top Result: {results['top_results'][0]['name']} ({results['top_results'][0]['similarity']:.3f})")
            
            print()
        else:
            print("‚ö†Ô∏è Comparison not available with basic retriever")
    
    def clear_cache(self):
        """Clear embedding cache"""
        print("\n" + "="*60)
        print("CLEAR CACHE")
        print("="*60)
        
        response = input("\n‚ö†Ô∏è This will delete all cached embeddings. Continue? (yes/no): ")
        if response.lower() not in ['yes', 'y']:
            print("‚ùå Cancelled")
            return
        
        if hasattr(self.retriever, 'clear_cache'):
            self.retriever.clear_cache()
            print("‚úÖ Cache cleared successfully")
        else:
            # Manual cleanup for basic retriever
            cache_dir = Path("data/cache")
            if cache_dir.exists():
                import shutil
                shutil.rmtree(cache_dir)
                print(f"‚úÖ Removed {cache_dir}")
            else:
                print("‚ö†Ô∏è No cache directory found")
        
        print()
    
    def benchmark(self, num_queries=10):
        """Benchmark embedding retrieval performance"""
        print("\n" + "="*60)
        print("BENCHMARK EMBEDDINGS")
        print("="*60)
        
        if not self.retriever.is_embeddings_ready():
            print("‚ùå Embeddings not ready. Run 'create' first.")
            return
        
        test_queries = [
            "top forwards",
            "best midfielders",
            "goalkeepers with clean sheets",
            "Man City players",
            "Arsenal attackers",
            "Liverpool midfielders",
            "highest scoring defenders",
            "value for money players",
            "consistent performers",
            "form players"
        ][:num_queries]
        
        print(f"\nüèÉ Running {len(test_queries)} test queries...")
        print()
        
        times = []
        for i, query in enumerate(test_queries, 1):
            start = time.time()
            results = self.retriever.embedding_retrieval(query, top_k=5)
            elapsed = time.time() - start
            times.append(elapsed)
            
            num_results = len(results.get('data', []))
            print(f"  {i}. '{query}': {elapsed:.3f}s ({num_results} results)")
        
        print()
        print("üìä Statistics:")
        print(f"   Total Time: {sum(times):.3f}s")
        print(f"   Average: {sum(times)/len(times):.3f}s")
        print(f"   Min: {min(times):.3f}s")
        print(f"   Max: {max(times):.3f}s")
        print()


def main():
    """Main entry point"""
    
    if len(sys.argv) < 2:
        print("Embedding Management Script")
        print("="*60)
        print("\nUsage:")
        print("  python manage_embeddings.py <command>")
        print("\nCommands:")
        print("  create    - Create embeddings for all players")
        print("  status    - Check cache status")
        print("  compare   - Compare different embedding models")
        print("  clear     - Clear embedding cache")
        print("  benchmark - Run performance benchmarks")
        print("\nExamples:")
        print("  python manage_embeddings.py create")
        print("  python manage_embeddings.py status")
        print("  python manage_embeddings.py compare")
        sys.exit(0)
    
    command = sys.argv[1].lower()
    
    try:
        manager = EmbeddingManager()
        
        if command == "create":
            manager.create_embeddings()
        
        elif command == "status":
            manager.check_status()
        
        elif command == "compare":
            manager.compare_models()
        
        elif command == "clear":
            manager.clear_cache()
        
        elif command == "benchmark":
            manager.benchmark()
        
        else:
            print(f"‚ùå Unknown command: {command}")
            print("Run without arguments to see available commands")
            sys.exit(1)
        
        manager.retriever.close()
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Interrupted by user")
        sys.exit(1)
    
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
